{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["#!pip install ipympl\n","#!pip install -U scikit-learn\n","#!pip install keras-vis"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1969,"status":"ok","timestamp":1624533765858,"user":{"displayName":"Yasuhiro Kubota","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpaWYUzbYg71o2yLv1rB7u5E5d0fdGKdx03dFTnWs=s64","userId":"05953776188019812919"},"user_tz":-540},"id":"kDTk0hMNRrvu","outputId":"2a4e4356-32c4-40dd-e3c9-20a56e6b1562"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-16 18:13:47.950103: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-16 18:13:48.601913: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"data":{"text/plain":["[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n"," PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["%reload_ext autoreload\n","%autoreload 2\n","import os\n","from tensorflow import keras\n","from matplotlib import pyplot as plt\n","from pennylane import numpy as np\n","from pennylane import numpy as np\n","import pennylane as qml\n","import tensorflow as tf\n","from tensorflow import keras\n","import matplotlib.pyplot as plt\n","import os\n","from datetime import datetime\n","from sklearn import preprocessing\n","\n","from IPython.display import display\n","%matplotlib inline\n"," \n","mnist_dataset = keras.datasets.mnist\n","(train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data()\n","\n","# Normalize pixel values within 0 and 1\n","train_images = train_images / (255)\n","test_images = test_images / (255)\n","\n","# Add extra dimension for convolution channels\n","train_images = np.array(train_images[..., tf.newaxis], requires_grad=False)\n","test_images = np.array(test_images[..., tf.newaxis], requires_grad=False)\n","\n","\n","#name of model or experiment\n","model_name = \"Q_Model\"\n","\n","n_epochs = 20   # Number of optimization epochs\n","n_layers = 1    # Number of random layers\n","n_batches = 64     # Size of the batches\n","\n","np.random.seed(0)           # Seed for NumPy random number generator\n","tf.random.set_seed(0)       # Seed for TensorFlow random number generator\n","\n","\n","tf.config.get_visible_devices()\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-16 18:13:50.733981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6795 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1715883232.999161    5128 service.cc:145] XLA service 0x7903d4002340 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","I0000 00:00:1715883232.999226    5128 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080, Compute Capability 7.5\n","2024-05-16 18:13:53.044212: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2024-05-16 18:13:53.118411: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m 17/938\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 10ms/step "]},{"name":"stderr","output_type":"stream","text":["I0000 00:00:1715883234.191099    5128 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 11ms/step\n","\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step\n","Epoch 1/20\n","938/938 - 3s - 3ms/step - accuracy: 0.8645 - loss: 0.4754 - val_accuracy: 0.9273 - val_loss: 0.2673\n","Epoch 2/20\n","938/938 - 2s - 2ms/step - accuracy: 0.9273 - loss: 0.2505 - val_accuracy: 0.9377 - val_loss: 0.2212\n","Epoch 3/20\n","938/938 - 2s - 2ms/step - accuracy: 0.9376 - loss: 0.2150 - val_accuracy: 0.9415 - val_loss: 0.2012\n","Epoch 4/20\n","938/938 - 2s - 2ms/step - accuracy: 0.9426 - loss: 0.1963 - val_accuracy: 0.9444 - val_loss: 0.1903\n","Epoch 5/20\n","938/938 - 2s - 2ms/step - accuracy: 0.9456 - loss: 0.1844 - val_accuracy: 0.9461 - val_loss: 0.1837\n","Epoch 6/20\n","938/938 - 2s - 2ms/step - accuracy: 0.9476 - loss: 0.1760 - val_accuracy: 0.9467 - val_loss: 0.1795\n","Epoch 7/20\n","938/938 - 2s - 2ms/step - accuracy: 0.9493 - loss: 0.1697 - val_accuracy: 0.9479 - val_loss: 0.1765\n","Epoch 8/20\n","938/938 - 2s - 2ms/step - accuracy: 0.9510 - loss: 0.1647 - val_accuracy: 0.9486 - val_loss: 0.1744\n","Epoch 9/20\n","938/938 - 2s - 2ms/step - accuracy: 0.9523 - loss: 0.1607 - val_accuracy: 0.9488 - val_loss: 0.1729\n","Epoch 10/20\n","938/938 - 2s - 2ms/step - accuracy: 0.9531 - loss: 0.1573 - val_accuracy: 0.9493 - val_loss: 0.1718\n","Epoch 11/20\n","938/938 - 2s - 2ms/step - accuracy: 0.9537 - loss: 0.1545 - val_accuracy: 0.9496 - val_loss: 0.1710\n","Epoch 12/20\n","938/938 - 2s - 2ms/step - accuracy: 0.9543 - loss: 0.1520 - val_accuracy: 0.9499 - val_loss: 0.1705\n","Epoch 13/20\n","938/938 - 2s - 2ms/step - accuracy: 0.9550 - loss: 0.1499 - val_accuracy: 0.9493 - val_loss: 0.1701\n","Epoch 14/20\n","938/938 - 2s - 2ms/step - accuracy: 0.9556 - loss: 0.1480 - val_accuracy: 0.9492 - val_loss: 0.1700\n","Epoch 15/20\n","938/938 - 2s - 2ms/step - accuracy: 0.9560 - loss: 0.1463 - val_accuracy: 0.9492 - val_loss: 0.1699\n","Epoch 16/20\n","938/938 - 2s - 2ms/step - accuracy: 0.9566 - loss: 0.1448 - val_accuracy: 0.9492 - val_loss: 0.1699\n","Epoch 17/20\n","938/938 - 2s - 2ms/step - accuracy: 0.9568 - loss: 0.1434 - val_accuracy: 0.9492 - val_loss: 0.1700\n","Epoch 18/20\n","938/938 - 2s - 2ms/step - accuracy: 0.9572 - loss: 0.1421 - val_accuracy: 0.9495 - val_loss: 0.1702\n","Epoch 19/20\n","938/938 - 2s - 2ms/step - accuracy: 0.9574 - loss: 0.1410 - val_accuracy: 0.9494 - val_loss: 0.1704\n","Epoch 20/20\n","938/938 - 2s - 2ms/step - accuracy: 0.9576 - loss: 0.1399 - val_accuracy: 0.9494 - val_loss: 0.1707\n"]}],"source":["\n","\n","n_qubits = 4\n","\n","rand_params = np.random.uniform(high=2 * np.pi, size=(n_layers, 4))\n","\n","dev = qml.device(\"default.qubit.tf\", wires=n_qubits)\n","\n","keras.utils.get_custom_objects().clear()\n","\n","@keras.utils.register_keras_serializable(package=(model_name+\"_Layer\"))\n","class ConvQLayer(keras.layers.Layer):\n","    \n","\n","    #replace the contents of qnode with experiment circuit\n","    @qml.qnode(dev, interface='tf')\n","    def q_node(inputs):\n","        inputs *= np.pi\n","        # Encoding of 4 classical input values\n","        #Further testing of the AngleEmbedding function is needed\n","        qml.AngleEmbedding(inputs, wires=range(n_qubits), rotation='Y')\n","        # Filter from arxiv.org/abs/2308.14930\n","\n","        qml.CNOT(wires=[1, 2])\n","        qml.CNOT(wires=[0, 3])\n","\n","        # Measurement producing 4 classical output values\n","        return [qml.expval(qml.PauliZ(j)) for j in range(n_qubits)]\n","\n","    def call(self, inputs):\n","\n","        #14x14 flattened 2x2 squares\n","        get_subsections_14x14 = lambda im : tf.reshape(tf.unstack(tf.reshape(im,[14,2,14,2]), axis = 2),[14,14,4])\n","\n","        #unpack 14x14 row by row\n","        list_squares_2x2 = lambda image_subsections: tf.reshape(tf.unstack(image_subsections, axis = 1), [196,4])\n","\n","\n","        #send 4 values to quantum function\n","        process_square_2x2 = lambda square_2x2 : self.q_node(square_2x2)\n","\n","        #send all squares to the quantum function wrapper\n","        process_subsections = lambda squares: tf.vectorized_map(process_square_2x2,squares)\n","\n","        #recompile the larger square\n","        separate_channels = lambda channel_stack: tf.reshape(channel_stack, [14,14,4])\n","        #each smaller square (channel) can be extracted as [:, :, channel]\n","        \n","        #apply function across batch\n","        preprocessing = lambda input: tf.vectorized_map(\n","            lambda image:(separate_channels(tf.transpose(process_subsections(list_squares_2x2(get_subsections_14x14(image)))))),\n","            input\n","        )\n","\n","        return preprocessing(inputs)\n","\n","qlayer = ConvQLayer()\n","\n","\n","#wrap preprocessing in model\n","\n","@keras.utils.register_keras_serializable(package=(model_name+\"_Pre_Model\"))\n","def Pre_Model():\n","    \"\"\"Initializes and returns a custom Keras model\n","    which is ready to be trained.\"\"\"\n","    model = keras.models.Sequential([\n","        qlayer\n","    ])\n","    model.compile(\n","        optimizer='adam',\n","        loss=\"sparse_categorical_crossentropy\",\n","        metrics=[\"accuracy\"],\n","    )\n","    return model\n","pre_model = Pre_Model()\n","\n","#core model\n","\n","@keras.utils.register_keras_serializable(package=(model_name+\"_Core_Model\"))\n","def Q_Model():\n","    \"\"\"Initializes and returns a custom Keras model\n","    which is ready to be trained.\"\"\"\n","    model = keras.models.Sequential([\n","        keras.layers.Flatten(),\n","        keras.layers.Dense(10, activation=\"softmax\")\n","    ])\n","    model.compile(\n","        optimizer='adam',\n","        loss=\"sparse_categorical_crossentropy\",\n","        metrics=[\"accuracy\"],\n","    )\n","    return model\n","\n","q_model = Q_Model()\n","\n","\n","#preprocessing\n","pre_train_images = pre_model.predict(train_images,batch_size=n_batches)\n","pre_test_images = pre_model.predict(test_images,batch_size=n_batches)\n","\n","#training\n","q_history = q_model.fit(\n","    pre_train_images,\n","    train_labels,\n","    validation_data=(pre_test_images, test_labels),\n","    batch_size = n_batches,\n","    epochs=n_epochs,\n","    verbose=2\n",")\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n","[5 0 4 1]\n","[5 0 4 1]\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","[5 0 4 1]\n","[5 0 4 1]\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n","</pre>\n"],"text/plain":["\u001b[1mModel: \"sequential_10\"\u001b[0m\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ rescaling_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv_q_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvQLayer</span>)       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n","</pre>\n"],"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n","│ rescaling_5 (\u001b[38;5;33mRescaling\u001b[0m)         │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ conv_q_layer (\u001b[38;5;33mConvQLayer\u001b[0m)       │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m4\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m784\u001b[0m)               │             \u001b[38;5;34m0\u001b[0m │\n","├─────────────────────────────────┼────────────────────────┼───────────────┤\n","│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m10\u001b[0m)                │         \u001b[38;5;34m7,850\u001b[0m │\n","└─────────────────────────────────┴────────────────────────┴───────────────┘\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> (30.66 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,850\u001b[0m (30.66 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> (30.66 KB)\n","</pre>\n"],"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,850\u001b[0m (30.66 KB)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"],"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["None"]},"metadata":{},"output_type":"display_data"},{"ename":"AttributeError","evalue":"'Dense' object has no attribute 'fit'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_labels[:\u001b[38;5;241m4\u001b[39m])\n\u001b[1;32m     26\u001b[0m display(full_model\u001b[38;5;241m.\u001b[39msummary())\n\u001b[0;32m---> 28\u001b[0m \u001b[43mfull_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m(full_model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m2\u001b[39m](full_model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m1\u001b[39m](full_model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m](train_images[:\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m255\u001b[39m))))\n","\u001b[0;31mAttributeError\u001b[0m: 'Dense' object has no attribute 'fit'"]}],"source":["input_model = Pre_Model()\n","\n","tr4 = input_model.predict(train_images[:4],batch_size=4)\n","\n","q_model_scaled = keras.models.Sequential([\n","    keras.layers.Rescaling(scale=1./127.5, offset=-1),\n","    q_model.layers[0],\n","    q_model.layers[1]\n","    ])\n","\n","print(np.argmax(q_model_scaled.predict((tr4[:4]+1)*127.5,batch_size=4), axis=1))\n","\n","print(train_labels[:4])\n","\n","full_model = keras.models.Sequential([\n","    keras.layers.Rescaling(scale=1./255),\n","    input_model.layers[0],\n","    q_model.layers[0],\n","    q_model.layers[1]\n","    ])\n","\n","print(np.argmax(full_model.predict(train_images[:4]*255,batch_size=4), axis=1))\n","\n","print(train_labels[:4])\n","\n","display(full_model.summary())\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_-JWct2iRrvy"},"source":["### Visualize"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"module 'keras.api.backend' has no attribute 'ndim'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 17\u001b[0m\n\u001b[1;32m     10\u001b[0m output_class \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m     12\u001b[0m losses \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     13\u001b[0m     (ActivationMaximization(full_model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m3\u001b[39m], output_class), \u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     14\u001b[0m     (LPNorm(full_model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minput), \u001b[38;5;241m10\u001b[39m),\n\u001b[1;32m     15\u001b[0m     (TotalVariation(full_model\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minput), \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     16\u001b[0m ]\n\u001b[0;32m---> 17\u001b[0m opt \u001b[38;5;241m=\u001b[39m \u001b[43mOptimizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m opt\u001b[38;5;241m.\u001b[39mminimize(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, input_modifiers\u001b[38;5;241m=\u001b[39m[Jitter()], callbacks\u001b[38;5;241m=\u001b[39m[GifGenerator(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopt_progress\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n","File \u001b[0;32m~/.local/lib/python3.12/site-packages/vis/optimizer.py:46\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, input_tensor, losses, input_range, wrt_tensor, norm_grads)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m loss, weight \u001b[38;5;129;01min\u001b[39;00m losses:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Perf optimization. Don't build loss function with 0 weight.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 46\u001b[0m         loss_fn \u001b[38;5;241m=\u001b[39m weight \u001b[38;5;241m*\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m         overall_loss \u001b[38;5;241m=\u001b[39m loss_fn \u001b[38;5;28;01mif\u001b[39;00m overall_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m overall_loss \u001b[38;5;241m+\u001b[39m loss_fn\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_names\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mname)\n","File \u001b[0;32m~/.local/lib/python3.12/site-packages/vis/losses.py:79\u001b[0m, in \u001b[0;36mActivationMaximization.build_loss\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer\u001b[38;5;241m.\u001b[39moutput\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# For all other layers it is 4\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m is_dense \u001b[38;5;241m=\u001b[39m \u001b[43mK\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m(layer_output) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     81\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_indices:\n","\u001b[0;31mAttributeError\u001b[0m: module 'keras.api.backend' has no attribute 'ndim'"]}],"source":["\n","from vis.losses import ActivationMaximization\n","from vis.regularizers import TotalVariation, LPNorm\n","from vis.input_modifiers import Jitter\n","from vis.optimizer import Optimizer\n","from vis.callbacks import GifGenerator\n","\n","# The name of the layer we want to visualize\n","# (see model definition in vggnet.py)\n","\n","output_class = [5]\n","\n","losses = [\n","    (ActivationMaximization(full_model.layers[3], output_class), 2),\n","    (LPNorm(full_model.layers[0].input), 10),\n","    (TotalVariation(full_model.layers[0].input), 10)\n","]\n","opt = Optimizer(full_model.layers[0].input, losses)\n","opt.minimize(max_iter=500, verbose=True, input_modifiers=[Jitter()], callbacks=[GifGenerator('opt_progress')])\n"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["['__annotations__',\n"," '__builtins__',\n"," '__call__',\n"," '__class__',\n"," '__closure__',\n"," '__code__',\n"," '__defaults__',\n"," '__delattr__',\n"," '__dict__',\n"," '__dir__',\n"," '__doc__',\n"," '__eq__',\n"," '__format__',\n"," '__ge__',\n"," '__get__',\n"," '__getattribute__',\n"," '__getstate__',\n"," '__globals__',\n"," '__gt__',\n"," '__hash__',\n"," '__init__',\n"," '__init_subclass__',\n"," '__kwdefaults__',\n"," '__le__',\n"," '__lt__',\n"," '__module__',\n"," '__name__',\n"," '__ne__',\n"," '__new__',\n"," '__qualname__',\n"," '__reduce__',\n"," '__reduce_ex__',\n"," '__repr__',\n"," '__setattr__',\n"," '__sizeof__',\n"," '__str__',\n"," '__subclasshook__',\n"," '__type_params__',\n"," '_api_export_path',\n"," '_api_export_symbol_id']"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["dir(keras.backend.ndim)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"visualize_dense_layer.ipynb","provenance":[{"file_id":"https://github.com/keisen/tf-keras-vis/blob/release%2Fv0.6.0/examples/visualize_dense_layer.ipynb","timestamp":1621656994610}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
