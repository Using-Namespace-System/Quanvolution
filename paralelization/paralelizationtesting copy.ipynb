{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 14:28:41.694498: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-14 14:28:41.694541: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-14 14:28:41.695476: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-14 14:28:41.701343: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-14 14:28:42.432099: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates import RandomLayers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "np.random.seed(0)           # Seed for NumPy random number generator\n",
    "tf.random.set_seed(0)       # Seed for TensorFlow random number generator\n",
    "\n",
    "mnist_dataset = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data()\n",
    "\n",
    "n_epochs = 1   # Number of optimization epochs\n",
    "n_layers = 1    # Number of random layers\n",
    "n_train = 20000    # Size of the train dataset\n",
    "n_test = 10000     # Size of the test dataset\n",
    "n_batches = 1     # Size of the batches\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 14:28:43.593323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 692 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080, pci bus id: 0000:b3:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Normalize pixel values within 0 and 1\n",
    "train_images = train_images / 255\n",
    "test_images = test_images / 255\n",
    "\n",
    "# Add extra dimension for convolution channels\n",
    "train_images = np.array(train_images[..., tf.newaxis], requires_grad=False)\n",
    "test_images = np.array(test_images[..., tf.newaxis], requires_grad=False)\n",
    "\n",
    "\n",
    "n_qubits = 4\n",
    "dev = qml.device(\"default.qubit.tf\", wires=n_qubits)\n",
    "\n",
    "\n",
    "@qml.qnode(dev, interface='tf')\n",
    "def qnotnode(inputs):\n",
    "    inputs *= np.pi\n",
    "    qml.AngleEmbedding(inputs, wires=range(n_qubits), rotation='Y')\n",
    "    qml.CNOT(wires=[1, 2])\n",
    "    qml.CNOT(wires=[0, 3])\n",
    "    return [qml.expval(qml.PauliZ(j)) for j in range(n_qubits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "process_square_2x2 = lambda square_2x2 : qnotnode(square_2x2)\n",
    "\n",
    "process_subsections = lambda squares: tf.vectorized_map(process_square_2x2,squares)\n",
    "\n",
    "list_squares_2x2 = lambda image_subsections: tf.reshape(tf.unstack(image_subsections, axis = 1), [196,4])\n",
    "\n",
    "get_subsections_14x14 = lambda im : tf.reshape(tf.unstack(tf.reshape(im,[14,2,14,2]), axis = 2),[14,14,4])\n",
    "\n",
    "separate_channels = lambda channel_stack: tf.reshape(channel_stack, [14,14,4])\n",
    "\n",
    "preprocessing = lambda input: tf.vectorized_map(\n",
    "    lambda image:(separate_channels(tf.transpose(process_subsections(list_squares_2x2(get_subsections_14x14(image)))))),\n",
    "    input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessed = preprocessing(train_images[:n_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 14, 4), dtype=int64, numpy=\n",
       "array([[[  0,   1,  28,  29],\n",
       "        [ 56,  57,  84,  85],\n",
       "        [112, 113, 140, 141],\n",
       "        [168, 169, 196, 197],\n",
       "        [224, 225, 252, 253],\n",
       "        [280, 281, 308, 309],\n",
       "        [336, 337, 364, 365],\n",
       "        [392, 393, 420, 421],\n",
       "        [448, 449, 476, 477],\n",
       "        [504, 505, 532, 533],\n",
       "        [560, 561, 588, 589],\n",
       "        [616, 617, 644, 645],\n",
       "        [672, 673, 700, 701],\n",
       "        [728, 729, 756, 757]],\n",
       "\n",
       "       [[  2,   3,  30,  31],\n",
       "        [ 58,  59,  86,  87],\n",
       "        [114, 115, 142, 143],\n",
       "        [170, 171, 198, 199],\n",
       "        [226, 227, 254, 255],\n",
       "        [282, 283, 310, 311],\n",
       "        [338, 339, 366, 367],\n",
       "        [394, 395, 422, 423],\n",
       "        [450, 451, 478, 479],\n",
       "        [506, 507, 534, 535],\n",
       "        [562, 563, 590, 591],\n",
       "        [618, 619, 646, 647],\n",
       "        [674, 675, 702, 703],\n",
       "        [730, 731, 758, 759]],\n",
       "\n",
       "       [[  4,   5,  32,  33],\n",
       "        [ 60,  61,  88,  89],\n",
       "        [116, 117, 144, 145],\n",
       "        [172, 173, 200, 201],\n",
       "        [228, 229, 256, 257],\n",
       "        [284, 285, 312, 313],\n",
       "        [340, 341, 368, 369],\n",
       "        [396, 397, 424, 425],\n",
       "        [452, 453, 480, 481],\n",
       "        [508, 509, 536, 537],\n",
       "        [564, 565, 592, 593],\n",
       "        [620, 621, 648, 649],\n",
       "        [676, 677, 704, 705],\n",
       "        [732, 733, 760, 761]],\n",
       "\n",
       "       [[  6,   7,  34,  35],\n",
       "        [ 62,  63,  90,  91],\n",
       "        [118, 119, 146, 147],\n",
       "        [174, 175, 202, 203],\n",
       "        [230, 231, 258, 259],\n",
       "        [286, 287, 314, 315],\n",
       "        [342, 343, 370, 371],\n",
       "        [398, 399, 426, 427],\n",
       "        [454, 455, 482, 483],\n",
       "        [510, 511, 538, 539],\n",
       "        [566, 567, 594, 595],\n",
       "        [622, 623, 650, 651],\n",
       "        [678, 679, 706, 707],\n",
       "        [734, 735, 762, 763]],\n",
       "\n",
       "       [[  8,   9,  36,  37],\n",
       "        [ 64,  65,  92,  93],\n",
       "        [120, 121, 148, 149],\n",
       "        [176, 177, 204, 205],\n",
       "        [232, 233, 260, 261],\n",
       "        [288, 289, 316, 317],\n",
       "        [344, 345, 372, 373],\n",
       "        [400, 401, 428, 429],\n",
       "        [456, 457, 484, 485],\n",
       "        [512, 513, 540, 541],\n",
       "        [568, 569, 596, 597],\n",
       "        [624, 625, 652, 653],\n",
       "        [680, 681, 708, 709],\n",
       "        [736, 737, 764, 765]],\n",
       "\n",
       "       [[ 10,  11,  38,  39],\n",
       "        [ 66,  67,  94,  95],\n",
       "        [122, 123, 150, 151],\n",
       "        [178, 179, 206, 207],\n",
       "        [234, 235, 262, 263],\n",
       "        [290, 291, 318, 319],\n",
       "        [346, 347, 374, 375],\n",
       "        [402, 403, 430, 431],\n",
       "        [458, 459, 486, 487],\n",
       "        [514, 515, 542, 543],\n",
       "        [570, 571, 598, 599],\n",
       "        [626, 627, 654, 655],\n",
       "        [682, 683, 710, 711],\n",
       "        [738, 739, 766, 767]],\n",
       "\n",
       "       [[ 12,  13,  40,  41],\n",
       "        [ 68,  69,  96,  97],\n",
       "        [124, 125, 152, 153],\n",
       "        [180, 181, 208, 209],\n",
       "        [236, 237, 264, 265],\n",
       "        [292, 293, 320, 321],\n",
       "        [348, 349, 376, 377],\n",
       "        [404, 405, 432, 433],\n",
       "        [460, 461, 488, 489],\n",
       "        [516, 517, 544, 545],\n",
       "        [572, 573, 600, 601],\n",
       "        [628, 629, 656, 657],\n",
       "        [684, 685, 712, 713],\n",
       "        [740, 741, 768, 769]],\n",
       "\n",
       "       [[ 14,  15,  42,  43],\n",
       "        [ 70,  71,  98,  99],\n",
       "        [126, 127, 154, 155],\n",
       "        [182, 183, 210, 211],\n",
       "        [238, 239, 266, 267],\n",
       "        [294, 295, 322, 323],\n",
       "        [350, 351, 378, 379],\n",
       "        [406, 407, 434, 435],\n",
       "        [462, 463, 490, 491],\n",
       "        [518, 519, 546, 547],\n",
       "        [574, 575, 602, 603],\n",
       "        [630, 631, 658, 659],\n",
       "        [686, 687, 714, 715],\n",
       "        [742, 743, 770, 771]],\n",
       "\n",
       "       [[ 16,  17,  44,  45],\n",
       "        [ 72,  73, 100, 101],\n",
       "        [128, 129, 156, 157],\n",
       "        [184, 185, 212, 213],\n",
       "        [240, 241, 268, 269],\n",
       "        [296, 297, 324, 325],\n",
       "        [352, 353, 380, 381],\n",
       "        [408, 409, 436, 437],\n",
       "        [464, 465, 492, 493],\n",
       "        [520, 521, 548, 549],\n",
       "        [576, 577, 604, 605],\n",
       "        [632, 633, 660, 661],\n",
       "        [688, 689, 716, 717],\n",
       "        [744, 745, 772, 773]],\n",
       "\n",
       "       [[ 18,  19,  46,  47],\n",
       "        [ 74,  75, 102, 103],\n",
       "        [130, 131, 158, 159],\n",
       "        [186, 187, 214, 215],\n",
       "        [242, 243, 270, 271],\n",
       "        [298, 299, 326, 327],\n",
       "        [354, 355, 382, 383],\n",
       "        [410, 411, 438, 439],\n",
       "        [466, 467, 494, 495],\n",
       "        [522, 523, 550, 551],\n",
       "        [578, 579, 606, 607],\n",
       "        [634, 635, 662, 663],\n",
       "        [690, 691, 718, 719],\n",
       "        [746, 747, 774, 775]],\n",
       "\n",
       "       [[ 20,  21,  48,  49],\n",
       "        [ 76,  77, 104, 105],\n",
       "        [132, 133, 160, 161],\n",
       "        [188, 189, 216, 217],\n",
       "        [244, 245, 272, 273],\n",
       "        [300, 301, 328, 329],\n",
       "        [356, 357, 384, 385],\n",
       "        [412, 413, 440, 441],\n",
       "        [468, 469, 496, 497],\n",
       "        [524, 525, 552, 553],\n",
       "        [580, 581, 608, 609],\n",
       "        [636, 637, 664, 665],\n",
       "        [692, 693, 720, 721],\n",
       "        [748, 749, 776, 777]],\n",
       "\n",
       "       [[ 22,  23,  50,  51],\n",
       "        [ 78,  79, 106, 107],\n",
       "        [134, 135, 162, 163],\n",
       "        [190, 191, 218, 219],\n",
       "        [246, 247, 274, 275],\n",
       "        [302, 303, 330, 331],\n",
       "        [358, 359, 386, 387],\n",
       "        [414, 415, 442, 443],\n",
       "        [470, 471, 498, 499],\n",
       "        [526, 527, 554, 555],\n",
       "        [582, 583, 610, 611],\n",
       "        [638, 639, 666, 667],\n",
       "        [694, 695, 722, 723],\n",
       "        [750, 751, 778, 779]],\n",
       "\n",
       "       [[ 24,  25,  52,  53],\n",
       "        [ 80,  81, 108, 109],\n",
       "        [136, 137, 164, 165],\n",
       "        [192, 193, 220, 221],\n",
       "        [248, 249, 276, 277],\n",
       "        [304, 305, 332, 333],\n",
       "        [360, 361, 388, 389],\n",
       "        [416, 417, 444, 445],\n",
       "        [472, 473, 500, 501],\n",
       "        [528, 529, 556, 557],\n",
       "        [584, 585, 612, 613],\n",
       "        [640, 641, 668, 669],\n",
       "        [696, 697, 724, 725],\n",
       "        [752, 753, 780, 781]],\n",
       "\n",
       "       [[ 26,  27,  54,  55],\n",
       "        [ 82,  83, 110, 111],\n",
       "        [138, 139, 166, 167],\n",
       "        [194, 195, 222, 223],\n",
       "        [250, 251, 278, 279],\n",
       "        [306, 307, 334, 335],\n",
       "        [362, 363, 390, 391],\n",
       "        [418, 419, 446, 447],\n",
       "        [474, 475, 502, 503],\n",
       "        [530, 531, 558, 559],\n",
       "        [586, 587, 614, 615],\n",
       "        [642, 643, 670, 671],\n",
       "        [698, 699, 726, 727],\n",
       "        [754, 755, 782, 783]]])>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_subsections_14x14(np.arange(784).reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(196, 4), dtype=int64, numpy=\n",
       "array([[  0,   1,  28,  29],\n",
       "       [  2,   3,  30,  31],\n",
       "       [  4,   5,  32,  33],\n",
       "       [  6,   7,  34,  35],\n",
       "       [  8,   9,  36,  37],\n",
       "       [ 10,  11,  38,  39],\n",
       "       [ 12,  13,  40,  41],\n",
       "       [ 14,  15,  42,  43],\n",
       "       [ 16,  17,  44,  45],\n",
       "       [ 18,  19,  46,  47],\n",
       "       [ 20,  21,  48,  49],\n",
       "       [ 22,  23,  50,  51],\n",
       "       [ 24,  25,  52,  53],\n",
       "       [ 26,  27,  54,  55],\n",
       "       [ 56,  57,  84,  85],\n",
       "       [ 58,  59,  86,  87],\n",
       "       [ 60,  61,  88,  89],\n",
       "       [ 62,  63,  90,  91],\n",
       "       [ 64,  65,  92,  93],\n",
       "       [ 66,  67,  94,  95],\n",
       "       [ 68,  69,  96,  97],\n",
       "       [ 70,  71,  98,  99],\n",
       "       [ 72,  73, 100, 101],\n",
       "       [ 74,  75, 102, 103],\n",
       "       [ 76,  77, 104, 105],\n",
       "       [ 78,  79, 106, 107],\n",
       "       [ 80,  81, 108, 109],\n",
       "       [ 82,  83, 110, 111],\n",
       "       [112, 113, 140, 141],\n",
       "       [114, 115, 142, 143],\n",
       "       [116, 117, 144, 145],\n",
       "       [118, 119, 146, 147],\n",
       "       [120, 121, 148, 149],\n",
       "       [122, 123, 150, 151],\n",
       "       [124, 125, 152, 153],\n",
       "       [126, 127, 154, 155],\n",
       "       [128, 129, 156, 157],\n",
       "       [130, 131, 158, 159],\n",
       "       [132, 133, 160, 161],\n",
       "       [134, 135, 162, 163],\n",
       "       [136, 137, 164, 165],\n",
       "       [138, 139, 166, 167],\n",
       "       [168, 169, 196, 197],\n",
       "       [170, 171, 198, 199],\n",
       "       [172, 173, 200, 201],\n",
       "       [174, 175, 202, 203],\n",
       "       [176, 177, 204, 205],\n",
       "       [178, 179, 206, 207],\n",
       "       [180, 181, 208, 209],\n",
       "       [182, 183, 210, 211],\n",
       "       [184, 185, 212, 213],\n",
       "       [186, 187, 214, 215],\n",
       "       [188, 189, 216, 217],\n",
       "       [190, 191, 218, 219],\n",
       "       [192, 193, 220, 221],\n",
       "       [194, 195, 222, 223],\n",
       "       [224, 225, 252, 253],\n",
       "       [226, 227, 254, 255],\n",
       "       [228, 229, 256, 257],\n",
       "       [230, 231, 258, 259],\n",
       "       [232, 233, 260, 261],\n",
       "       [234, 235, 262, 263],\n",
       "       [236, 237, 264, 265],\n",
       "       [238, 239, 266, 267],\n",
       "       [240, 241, 268, 269],\n",
       "       [242, 243, 270, 271],\n",
       "       [244, 245, 272, 273],\n",
       "       [246, 247, 274, 275],\n",
       "       [248, 249, 276, 277],\n",
       "       [250, 251, 278, 279],\n",
       "       [280, 281, 308, 309],\n",
       "       [282, 283, 310, 311],\n",
       "       [284, 285, 312, 313],\n",
       "       [286, 287, 314, 315],\n",
       "       [288, 289, 316, 317],\n",
       "       [290, 291, 318, 319],\n",
       "       [292, 293, 320, 321],\n",
       "       [294, 295, 322, 323],\n",
       "       [296, 297, 324, 325],\n",
       "       [298, 299, 326, 327],\n",
       "       [300, 301, 328, 329],\n",
       "       [302, 303, 330, 331],\n",
       "       [304, 305, 332, 333],\n",
       "       [306, 307, 334, 335],\n",
       "       [336, 337, 364, 365],\n",
       "       [338, 339, 366, 367],\n",
       "       [340, 341, 368, 369],\n",
       "       [342, 343, 370, 371],\n",
       "       [344, 345, 372, 373],\n",
       "       [346, 347, 374, 375],\n",
       "       [348, 349, 376, 377],\n",
       "       [350, 351, 378, 379],\n",
       "       [352, 353, 380, 381],\n",
       "       [354, 355, 382, 383],\n",
       "       [356, 357, 384, 385],\n",
       "       [358, 359, 386, 387],\n",
       "       [360, 361, 388, 389],\n",
       "       [362, 363, 390, 391],\n",
       "       [392, 393, 420, 421],\n",
       "       [394, 395, 422, 423],\n",
       "       [396, 397, 424, 425],\n",
       "       [398, 399, 426, 427],\n",
       "       [400, 401, 428, 429],\n",
       "       [402, 403, 430, 431],\n",
       "       [404, 405, 432, 433],\n",
       "       [406, 407, 434, 435],\n",
       "       [408, 409, 436, 437],\n",
       "       [410, 411, 438, 439],\n",
       "       [412, 413, 440, 441],\n",
       "       [414, 415, 442, 443],\n",
       "       [416, 417, 444, 445],\n",
       "       [418, 419, 446, 447],\n",
       "       [448, 449, 476, 477],\n",
       "       [450, 451, 478, 479],\n",
       "       [452, 453, 480, 481],\n",
       "       [454, 455, 482, 483],\n",
       "       [456, 457, 484, 485],\n",
       "       [458, 459, 486, 487],\n",
       "       [460, 461, 488, 489],\n",
       "       [462, 463, 490, 491],\n",
       "       [464, 465, 492, 493],\n",
       "       [466, 467, 494, 495],\n",
       "       [468, 469, 496, 497],\n",
       "       [470, 471, 498, 499],\n",
       "       [472, 473, 500, 501],\n",
       "       [474, 475, 502, 503],\n",
       "       [504, 505, 532, 533],\n",
       "       [506, 507, 534, 535],\n",
       "       [508, 509, 536, 537],\n",
       "       [510, 511, 538, 539],\n",
       "       [512, 513, 540, 541],\n",
       "       [514, 515, 542, 543],\n",
       "       [516, 517, 544, 545],\n",
       "       [518, 519, 546, 547],\n",
       "       [520, 521, 548, 549],\n",
       "       [522, 523, 550, 551],\n",
       "       [524, 525, 552, 553],\n",
       "       [526, 527, 554, 555],\n",
       "       [528, 529, 556, 557],\n",
       "       [530, 531, 558, 559],\n",
       "       [560, 561, 588, 589],\n",
       "       [562, 563, 590, 591],\n",
       "       [564, 565, 592, 593],\n",
       "       [566, 567, 594, 595],\n",
       "       [568, 569, 596, 597],\n",
       "       [570, 571, 598, 599],\n",
       "       [572, 573, 600, 601],\n",
       "       [574, 575, 602, 603],\n",
       "       [576, 577, 604, 605],\n",
       "       [578, 579, 606, 607],\n",
       "       [580, 581, 608, 609],\n",
       "       [582, 583, 610, 611],\n",
       "       [584, 585, 612, 613],\n",
       "       [586, 587, 614, 615],\n",
       "       [616, 617, 644, 645],\n",
       "       [618, 619, 646, 647],\n",
       "       [620, 621, 648, 649],\n",
       "       [622, 623, 650, 651],\n",
       "       [624, 625, 652, 653],\n",
       "       [626, 627, 654, 655],\n",
       "       [628, 629, 656, 657],\n",
       "       [630, 631, 658, 659],\n",
       "       [632, 633, 660, 661],\n",
       "       [634, 635, 662, 663],\n",
       "       [636, 637, 664, 665],\n",
       "       [638, 639, 666, 667],\n",
       "       [640, 641, 668, 669],\n",
       "       [642, 643, 670, 671],\n",
       "       [672, 673, 700, 701],\n",
       "       [674, 675, 702, 703],\n",
       "       [676, 677, 704, 705],\n",
       "       [678, 679, 706, 707],\n",
       "       [680, 681, 708, 709],\n",
       "       [682, 683, 710, 711],\n",
       "       [684, 685, 712, 713],\n",
       "       [686, 687, 714, 715],\n",
       "       [688, 689, 716, 717],\n",
       "       [690, 691, 718, 719],\n",
       "       [692, 693, 720, 721],\n",
       "       [694, 695, 722, 723],\n",
       "       [696, 697, 724, 725],\n",
       "       [698, 699, 726, 727],\n",
       "       [728, 729, 756, 757],\n",
       "       [730, 731, 758, 759],\n",
       "       [732, 733, 760, 761],\n",
       "       [734, 735, 762, 763],\n",
       "       [736, 737, 764, 765],\n",
       "       [738, 739, 766, 767],\n",
       "       [740, 741, 768, 769],\n",
       "       [742, 743, 770, 771],\n",
       "       [744, 745, 772, 773],\n",
       "       [746, 747, 774, 775],\n",
       "       [748, 749, 776, 777],\n",
       "       [750, 751, 778, 779],\n",
       "       [752, 753, 780, 781],\n",
       "       [754, 755, 782, 783]])>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_squares_2x2(get_subsections_14x14(np.arange(784).reshape(28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "  preprocessed_cpu_1 = tf.identity(preprocessed)\n",
    "\n",
    "preprocessed = preprocessing(train_images[n_train:n_train*2])\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "  preprocessed_cpu_2 = tf.identity(preprocessed)\n",
    "\n",
    "preprocessed = preprocessing(train_images[n_train*2:n_train*3])\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "  preprocessed_training_cpu = tf.reshape(tf.stack([preprocessed_cpu_1,preprocessed_cpu_2,tf.identity(preprocessed)]),[n_train*3,14,14,4])\n",
    "\n",
    "train_labels = train_labels[:n_train*3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_titles = ['Five-Ch1', 'Five-Ch2', 'Five-Ch3','Five-Ch4']\n",
    "f, ax = plt.subplots(nrows=1, ncols=4, figsize=(12, 4))\n",
    "for i, title in enumerate(image_titles):\n",
    "    ax[i].set_title(title, fontsize=16)\n",
    "    ax[i].imshow(preprocessed_training_cpu[0][:,:,i])\n",
    "    ax[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QML-QPF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
