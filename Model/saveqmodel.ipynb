{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1969,"status":"ok","timestamp":1624533765858,"user":{"displayName":"Yasuhiro Kubota","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpaWYUzbYg71o2yLv1rB7u5E5d0fdGKdx03dFTnWs=s64","userId":"05953776188019812919"},"user_tz":-540},"id":"kDTk0hMNRrvu","outputId":"2a4e4356-32c4-40dd-e3c9-20a56e6b1562"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-05-10 21:52:05.379138: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-05-10 21:52:05.379185: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-05-10 21:52:05.380148: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-05-10 21:52:05.385983: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-05-10 21:52:06.036914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]},{"name":"stdout","output_type":"stream","text":["Tensorflow recognized 0 GPUs\n"]},{"name":"stderr","output_type":"stream","text":["2024-05-10 21:52:06.862628: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n","2024-05-10 21:52:06.862703: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: 0ff20dead65f\n","2024-05-10 21:52:06.862738: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: 0ff20dead65f\n","2024-05-10 21:52:06.862909: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 550.54.15\n","2024-05-10 21:52:06.862963: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 550.54.15\n","2024-05-10 21:52:06.862984: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 550.54.15\n"]}],"source":["%reload_ext autoreload\n","%autoreload 2\n"," \n","from matplotlib import pyplot as plt\n","%matplotlib inline\n"," \n","import tensorflow as tf\n","from tf_keras_vis.utils import num_of_gpus\n"," \n","_, gpus = num_of_gpus()\n","print('Tensorflow recognized {} GPUs'.format(gpus))"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/30\n","20/20 - 2s - loss: 3.0419 - accuracy: 0.2750 - val_loss: 2.4549 - val_accuracy: 0.3333 - 2s/epoch - 86ms/step\n","Epoch 2/30\n","20/20 - 2s - loss: 1.5368 - accuracy: 0.4625 - val_loss: 1.2140 - val_accuracy: 0.6667 - 2s/epoch - 78ms/step\n","Epoch 3/30\n","20/20 - 2s - loss: 0.7850 - accuracy: 0.7375 - val_loss: 1.4766 - val_accuracy: 0.6333 - 2s/epoch - 76ms/step\n","Epoch 4/30\n","20/20 - 2s - loss: 0.5034 - accuracy: 0.8875 - val_loss: 0.9045 - val_accuracy: 0.6667 - 2s/epoch - 79ms/step\n","Epoch 5/30\n","20/20 - 2s - loss: 0.3459 - accuracy: 0.9375 - val_loss: 1.0090 - val_accuracy: 0.7667 - 2s/epoch - 75ms/step\n","Epoch 6/30\n","20/20 - 1s - loss: 0.3252 - accuracy: 0.9125 - val_loss: 1.0446 - val_accuracy: 0.6667 - 1s/epoch - 72ms/step\n","Epoch 7/30\n","20/20 - 2s - loss: 0.2414 - accuracy: 0.9375 - val_loss: 0.9025 - val_accuracy: 0.7333 - 2s/epoch - 76ms/step\n","Epoch 8/30\n","20/20 - 1s - loss: 0.1628 - accuracy: 0.9625 - val_loss: 0.8812 - val_accuracy: 0.7333 - 1s/epoch - 71ms/step\n","Epoch 9/30\n","20/20 - 1s - loss: 0.1502 - accuracy: 0.9625 - val_loss: 0.8839 - val_accuracy: 0.7333 - 1s/epoch - 74ms/step\n","Epoch 10/30\n","20/20 - 2s - loss: 0.0698 - accuracy: 1.0000 - val_loss: 0.9539 - val_accuracy: 0.7000 - 2s/epoch - 78ms/step\n","Epoch 11/30\n","20/20 - 2s - loss: 0.0470 - accuracy: 1.0000 - val_loss: 0.7863 - val_accuracy: 0.7667 - 2s/epoch - 78ms/step\n","Epoch 12/30\n","20/20 - 1s - loss: 0.0446 - accuracy: 1.0000 - val_loss: 0.8408 - val_accuracy: 0.7667 - 1s/epoch - 73ms/step\n","Epoch 13/30\n","20/20 - 2s - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.8429 - val_accuracy: 0.7667 - 2s/epoch - 77ms/step\n","Epoch 14/30\n","20/20 - 2s - loss: 0.0358 - accuracy: 1.0000 - val_loss: 0.8846 - val_accuracy: 0.7333 - 2s/epoch - 75ms/step\n","Epoch 15/30\n","20/20 - 2s - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.8415 - val_accuracy: 0.7333 - 2s/epoch - 77ms/step\n","Epoch 16/30\n","20/20 - 2s - loss: 0.0389 - accuracy: 1.0000 - val_loss: 0.9510 - val_accuracy: 0.7333 - 2s/epoch - 77ms/step\n","Epoch 17/30\n","20/20 - 1s - loss: 0.0386 - accuracy: 1.0000 - val_loss: 1.0933 - val_accuracy: 0.6333 - 1s/epoch - 73ms/step\n","Epoch 18/30\n","20/20 - 2s - loss: 0.0920 - accuracy: 0.9750 - val_loss: 0.8005 - val_accuracy: 0.7000 - 2s/epoch - 76ms/step\n","Epoch 19/30\n","20/20 - 2s - loss: 0.0765 - accuracy: 0.9875 - val_loss: 1.6344 - val_accuracy: 0.5333 - 2s/epoch - 76ms/step\n","Epoch 20/30\n","20/20 - 2s - loss: 0.0592 - accuracy: 0.9875 - val_loss: 0.7973 - val_accuracy: 0.7333 - 2s/epoch - 79ms/step\n","Epoch 21/30\n","20/20 - 1s - loss: 0.0282 - accuracy: 1.0000 - val_loss: 1.0371 - val_accuracy: 0.7333 - 1s/epoch - 71ms/step\n","Epoch 22/30\n","20/20 - 2s - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.7565 - val_accuracy: 0.7667 - 2s/epoch - 76ms/step\n","Epoch 23/30\n","20/20 - 1s - loss: 0.0150 - accuracy: 1.0000 - val_loss: 0.8462 - val_accuracy: 0.7000 - 1s/epoch - 72ms/step\n","Epoch 24/30\n","20/20 - 1s - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.8076 - val_accuracy: 0.7333 - 1s/epoch - 70ms/step\n","Epoch 25/30\n","20/20 - 2s - loss: 0.0118 - accuracy: 1.0000 - val_loss: 0.8271 - val_accuracy: 0.7667 - 2s/epoch - 75ms/step\n","Epoch 26/30\n","20/20 - 1s - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.8184 - val_accuracy: 0.7667 - 1s/epoch - 72ms/step\n","Epoch 27/30\n","20/20 - 1s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.8313 - val_accuracy: 0.7333 - 1s/epoch - 72ms/step\n","Epoch 28/30\n","20/20 - 1s - loss: 0.0105 - accuracy: 1.0000 - val_loss: 0.8151 - val_accuracy: 0.7000 - 1s/epoch - 72ms/step\n","Epoch 29/30\n","20/20 - 1s - loss: 0.0098 - accuracy: 1.0000 - val_loss: 0.8298 - val_accuracy: 0.7000 - 1s/epoch - 72ms/step\n","Epoch 30/30\n","20/20 - 2s - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.8122 - val_accuracy: 0.7667 - 2s/epoch - 77ms/step\n"]}],"source":["import pennylane as qml\n","from pennylane import numpy as np\n","from tensorflow import keras\n","\n","mnist_dataset = keras.datasets.mnist\n","(train_images, train_labels), (test_images, test_labels) = mnist_dataset.load_data()\n","\n","n_epochs = 30   # Number of optimization epochs\n","n_layers = 1    # Number of random layers\n","n_train = 80    # Size of the train dataset\n","n_test = 30     # Size of the test dataset\n","n_batches = 4     # Size of the batches\n","\n","# Reduce dataset size\n","train_images = train_images[:n_train]\n","train_labels = train_labels[:n_train]\n","test_images = test_images[:n_test]\n","test_labels = test_labels[:n_test]\n","\n","# Normalize pixel values within 0 and 1\n","train_images = train_images / 255\n","test_images = test_images / 255\n","\n","# Add extra dimension for convolution channels\n","train_images = np.array(train_images[..., tf.newaxis], requires_grad=False)\n","test_images = np.array(test_images[..., tf.newaxis], requires_grad=False)\n","\n","n_qubits = 4\n","\n","dev = qml.device(\"default.qubit\", wires=n_qubits)\n","\n","@qml.qnode(dev, interface='tf')\n","def qnotnode(inputs):\n","    inputs *= np.pi\n","    # Encoding of 4 classical input values\n","    qml.AngleEmbedding(inputs, wires=range(n_qubits), rotation='Y')\n","\n","    # Filter from arxiv.org/abs/2308.14930\n","\n","    qml.CNOT(wires=[1, 2])\n","    qml.CNOT(wires=[0, 3])\n","\n","\n","    # Measurement producing 4 classical output values\n","    return [qml.expval(qml.PauliZ(j)) for j in range(n_qubits)]\n","\n","class ConvQLayer(qml.qnn.KerasLayer):\n","    \n","    def call(self, inputs):\n","\n","        out = tf.Variable(tf.zeros((n_batches, 14, 14, n_qubits)))\n","        for b in range(n_batches):\n","            # Loop over the coordinates of the top-left pixel of 2X2 squares\n","            for j in range(0, 28, 2):\n","                for k in range(0, 28, 2):\n","                    # Process a squared 2x2 region of the image with a quantum circuit\n","                    q_results = tf.stack(\n","                        [\n","                            inputs[b,j, k, 0],\n","                            inputs[b,j, k + 1, 0],\n","                            inputs[b,j + 1, k, 0],\n","                            inputs[b,j + 1, k + 1, 0]\n","                        ],\n","                        axis = 1\n","                    )\n","                    q_results = super().call(q_results)\n","                    # Assign expectation values to different channels of the output pixel (j/2, k/2)\n","                    for c in range(n_qubits):\n","                        out[b,j // 2, k // 2, c] = q_results[c]\n","        return out \n","\n","qnotlayer = qml.qnn.KerasLayer(qnotnode, {}, output_dim=[28,28,n_qubits])\n","\n","qnotlayer.trainable = False\n","\n","def Qnot_Model():\n","    \"\"\"Initializes and returns a custom Keras model\n","    which is ready to be trained.\"\"\"\n","    model = keras.models.Sequential([\n","        qnotlayer,\n","        keras.layers.Flatten(),\n","        keras.layers.Dense(10, activation=\"softmax\")\n","    ])\n","    model.compile(\n","        optimizer='adam',\n","        loss=\"sparse_categorical_crossentropy\",\n","        metrics=[\"accuracy\"]\n","    )\n","    return model\n","\n","qnot_model = Qnot_Model()\n","\n","qnot_history = qnot_model.fit(\n","    train_images,\n","    train_labels,\n","    validation_data=(test_images, test_labels),\n","    batch_size = n_batches,\n","    epochs=n_epochs,\n","    verbose=2\n",")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1436,"status":"ok","timestamp":1624533767271,"user":{"displayName":"Yasuhiro Kubota","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjpaWYUzbYg71o2yLv1rB7u5E5d0fdGKdx03dFTnWs=s64","userId":"05953776188019812919"},"user_tz":-540},"id":"bex_VD7tRrvw","outputId":"0f4bc9d2-fd7e-49ee-fc0c-bda598a64995"},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," keras_layer (KerasLayer)    (None, 28, 28, 4)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 3136)              0         \n","                                                                 \n"," dense (Dense)               (None, 10)                31370     \n","                                                                 \n","=================================================================\n","Total params: 31370 (122.54 KB)\n","Trainable params: 31370 (122.54 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["model = qnot_model\n","model.summary()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <function _gcd_import at 0x7999938d7d80> and will run it as-is.\n","Cause: Unable to locate the source code of <function _gcd_import at 0x7999938d7d80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","WARNING: AutoGraph could not transform <function _gcd_import at 0x7999938d7d80> and will run it as-is.\n","Cause: Unable to locate the source code of <function _gcd_import at 0x7999938d7d80>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n","INFO:tensorflow:Assets written to: model/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: model/assets\n"]}],"source":["model.save('model')"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["load = keras.models.load_model('model')"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," keras_layer (KerasLayer)    (None, 28, 28, 4)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 3136)              0         \n","                                                                 \n"," dense (Dense)               (None, 10)                31370     \n","                                                                 \n","=================================================================\n","Total params: 31370 (122.54 KB)\n","Trainable params: 31370 (122.54 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["load.summary()"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["<tf.Tensor: shape=(80, 10), dtype=float32, numpy=\n","array([[1.20761991e-03, 3.74046667e-03, 1.63640396e-03, 1.00690871e-02,\n","        1.57830436e-04, 9.74630535e-01, 2.90802657e-03, 1.49816988e-04,\n","        8.48014082e-04, 4.65216162e-03],\n","       [9.98854995e-01, 1.51292425e-05, 2.95401769e-05, 2.14092543e-05,\n","        1.99213919e-05, 6.95564027e-04, 1.17945106e-04, 1.55700909e-04,\n","        8.39427739e-05, 5.66017752e-06],\n","       [1.44867863e-05, 6.04510433e-06, 3.53058203e-05, 4.22612386e-04,\n","        9.99143243e-01, 6.27362751e-05, 2.12458690e-04, 1.89848215e-05,\n","        4.77247204e-06, 7.92992796e-05],\n","       [4.15370960e-05, 9.88576651e-01, 4.49136598e-04, 1.67416380e-04,\n","        2.69370852e-03, 1.17553724e-03, 3.42138192e-05, 2.83637521e-04,\n","        6.50315871e-03, 7.50219697e-05],\n","       [9.51909169e-05, 6.65323809e-04, 2.47278775e-04, 9.34424825e-05,\n","        6.02936186e-03, 1.19991681e-04, 5.59484935e-04, 4.96992003e-03,\n","        3.02921608e-03, 9.84190762e-01],\n","       [1.00870919e-03, 4.50073021e-05, 9.89468396e-01, 1.12498892e-04,\n","        5.26125950e-04, 8.53101898e-04, 9.52221453e-04, 5.75203856e-04,\n","        2.78871669e-03, 3.66999628e-03],\n","       [1.04233068e-05, 9.95573103e-01, 5.32191989e-05, 1.21695537e-03,\n","        2.83152389e-04, 1.55585134e-04, 2.93996127e-04, 2.09493723e-04,\n","        2.29675192e-04, 1.97435310e-03],\n","       [4.74190427e-04, 4.81548750e-06, 3.43767204e-03, 9.87254977e-01,\n","        3.37459409e-04, 5.30791120e-04, 7.63769349e-05, 8.75098536e-08,\n","        6.54618768e-03, 1.33737084e-03],\n","       [2.72211018e-05, 9.89353418e-01, 6.92819376e-05, 7.92150560e-04,\n","        6.74980925e-04, 1.51391479e-03, 7.78286834e-04, 1.26697251e-03,\n","        3.58418300e-04, 5.16534224e-03],\n","       [1.96910787e-05, 2.66577590e-05, 5.36445114e-05, 2.45132596e-05,\n","        9.91538167e-01, 3.16487532e-03, 2.89493270e-04, 4.00136312e-04,\n","        2.65260518e-04, 4.21748823e-03],\n","       [7.64610362e-04, 2.09997827e-03, 1.30855455e-03, 9.92305875e-01,\n","        9.67942105e-06, 9.38172045e-04, 1.03250997e-04, 2.24873093e-05,\n","        6.71995571e-04, 1.77544344e-03],\n","       [5.87075265e-05, 5.34113683e-03, 8.13862775e-04, 2.42002454e-04,\n","        4.83060768e-03, 9.86486256e-01, 1.09751883e-04, 8.48013500e-04,\n","        8.64492962e-04, 4.05159226e-04],\n","       [5.30644138e-05, 4.80197968e-06, 1.64802244e-04, 9.99696374e-01,\n","        4.28155436e-05, 1.66049413e-05, 3.59086835e-06, 2.96549132e-07,\n","        4.37494691e-06, 1.32411014e-05],\n","       [2.36119871e-04, 6.45779946e-04, 5.53857186e-04, 5.58643887e-06,\n","        4.76199156e-03, 1.35806273e-04, 9.93193567e-01, 1.57941962e-04,\n","        1.51290456e-04, 1.57821356e-04],\n","       [2.34694289e-05, 9.93154287e-01, 7.86912424e-05, 5.61212713e-04,\n","        4.48791398e-04, 1.69671432e-03, 3.28618014e-04, 4.69638908e-04,\n","        2.08979953e-04, 3.02951410e-03],\n","       [1.80492309e-04, 1.65060192e-05, 1.25138366e-04, 1.00030127e-06,\n","        1.05259998e-03, 6.08668815e-05, 4.06548270e-06, 9.78656173e-01,\n","        1.39962780e-04, 1.97632052e-02],\n","       [8.11691454e-04, 1.70415107e-04, 9.91369009e-01, 8.72820325e-04,\n","        6.39112433e-04, 1.80971029e-03, 1.25482577e-04, 3.18560936e-03,\n","        5.82164677e-04, 4.34002490e-04],\n","       [9.72019261e-05, 1.19174052e-04, 1.04780593e-04, 6.53192474e-05,\n","        8.16704323e-06, 1.25515671e-03, 2.59329117e-05, 6.28506386e-05,\n","        9.90292192e-01, 7.96920434e-03],\n","       [4.16886498e-04, 1.13361212e-03, 1.70746018e-04, 5.92214637e-04,\n","        2.59234128e-03, 5.04166528e-04, 9.90275919e-01, 8.97368882e-05,\n","        5.30469624e-05, 4.17154375e-03],\n","       [8.39199129e-05, 1.09441043e-03, 1.02302532e-04, 2.99060630e-04,\n","        6.44455082e-04, 2.07696459e-03, 1.41715034e-04, 2.93307216e-03,\n","        2.03129207e-03, 9.90592778e-01],\n","       [3.00665979e-05, 3.52403435e-06, 6.44931453e-04, 3.83531587e-04,\n","        9.98277545e-01, 5.23525568e-06, 1.48488354e-04, 1.87048627e-05,\n","        3.47806745e-05, 4.53142333e-04],\n","       [9.98749673e-01, 3.86748834e-05, 3.50309638e-05, 6.65503539e-05,\n","        2.42042952e-05, 5.73716650e-04, 2.87425428e-05, 4.13997826e-04,\n","        6.02539367e-05, 9.10198196e-06],\n","       [2.13329797e-04, 2.33363383e-03, 3.16066435e-04, 6.84211409e-05,\n","        3.93774593e-03, 7.78995163e-04, 2.90836720e-03, 3.16355331e-03,\n","        5.17741498e-03, 9.81102347e-01],\n","       [4.47875136e-05, 9.86832440e-01, 5.90464741e-04, 2.09713267e-04,\n","        3.59310419e-03, 1.26496737e-03, 4.71239437e-05, 8.05252115e-04,\n","        6.45841938e-03, 1.53606656e-04],\n","       [6.36873068e-04, 9.74491119e-01, 6.40386017e-04, 1.63325074e-03,\n","        1.17932541e-04, 4.44670347e-03, 6.66246796e-03, 9.07028839e-03,\n","        5.17095614e-04, 1.78390590e-03],\n","       [2.60662055e-03, 2.15888176e-05, 9.90996718e-01, 4.33387561e-03,\n","        1.20221694e-06, 1.67941645e-04, 1.95099910e-05, 1.16768364e-08,\n","        1.82646548e-03, 2.60570068e-05],\n","       [4.69853585e-05, 1.35261717e-03, 3.50337970e-04, 1.41518761e-03,\n","        9.77962732e-01, 1.35070668e-03, 5.23920404e-04, 8.96385964e-03,\n","        4.05665167e-04, 7.62784388e-03],\n","       [6.58616191e-05, 7.33314494e-08, 4.28866973e-04, 9.99273300e-01,\n","        6.06633364e-07, 3.04492951e-05, 5.92277331e-07, 5.82135584e-08,\n","        1.80138362e-04, 2.01042312e-05],\n","       [1.45262759e-03, 7.82543430e-06, 9.95986104e-01, 2.49998353e-04,\n","        6.33688906e-05, 1.24726794e-04, 2.70408577e-06, 1.59679819e-03,\n","        1.09919529e-04, 4.05854895e-04],\n","       [8.86573980e-05, 1.15578240e-02, 5.32731763e-04, 4.99024718e-05,\n","        6.25171559e-03, 9.30486305e-04, 7.26016820e-04, 9.77661967e-01,\n","        7.81570678e-04, 1.41907448e-03],\n","       [2.72655343e-05, 2.35003605e-03, 1.11189915e-03, 9.89551723e-01,\n","        9.33006522e-04, 1.14073395e-03, 1.14564598e-03, 7.26427999e-04,\n","        1.00712197e-04, 2.91251624e-03],\n","       [7.46068370e-04, 5.14530437e-03, 2.46493286e-03, 2.71406898e-04,\n","        6.60647765e-06, 1.37465086e-03, 1.95176235e-05, 1.03886323e-05,\n","        9.88933980e-01, 1.02702552e-03],\n","       [8.76433696e-05, 5.11791732e-04, 1.87000333e-04, 1.71418127e-04,\n","        1.99847273e-03, 1.21004682e-03, 9.94754314e-01, 3.78443539e-04,\n","        8.46301828e-06, 6.92409580e-04],\n","       [8.02898576e-05, 5.52538433e-04, 3.25290253e-04, 1.14084542e-04,\n","        6.24850683e-04, 7.84026517e-04, 3.65931664e-05, 1.68595742e-02,\n","        1.59728678e-03, 9.79025304e-01],\n","       [9.87336218e-01, 6.75989895e-06, 2.22009909e-03, 1.22789934e-03,\n","        1.29695909e-04, 5.46595256e-04, 3.82026867e-03, 6.83065591e-05,\n","        4.57684603e-03, 6.73411341e-05],\n","       [1.53243091e-04, 5.03727840e-03, 2.46919895e-04, 2.41660490e-03,\n","        1.41125440e-03, 9.87941027e-01, 9.16714198e-05, 1.11477484e-03,\n","        1.49809755e-04, 1.43723923e-03],\n","       [1.99308906e-05, 1.82487129e-03, 1.94089327e-04, 1.12165220e-03,\n","        4.57672228e-04, 1.46545994e-04, 9.95784581e-01, 3.76594016e-06,\n","        2.14959029e-04, 2.32007791e-04],\n","       [9.98955727e-01, 7.82269012e-07, 2.54865881e-04, 1.25460383e-05,\n","        1.95634984e-05, 3.03112785e-04, 3.87844280e-04, 3.56747150e-05,\n","        2.63137426e-05, 3.55777274e-06],\n","       [5.63654903e-05, 3.82368744e-04, 3.63169936e-03, 1.13468908e-03,\n","        3.16277216e-03, 2.09617021e-04, 4.98064037e-04, 9.88547385e-01,\n","        9.34647513e-04, 1.44234288e-03],\n","       [9.62273916e-05, 9.81054200e-06, 1.72970278e-04, 8.22686889e-06,\n","        7.16682407e-05, 2.27604978e-05, 9.99231577e-01, 8.22908478e-05,\n","        1.00903690e-05, 2.94536119e-04],\n","       [1.86630132e-05, 9.95948136e-01, 9.62884151e-05, 1.00480719e-03,\n","        2.35086227e-05, 4.79924522e-04, 1.25382838e-04, 4.79241193e-04,\n","        5.64879912e-04, 1.25913613e-03],\n","       [4.82993608e-04, 9.42552462e-04, 1.63112290e-03, 4.57282178e-04,\n","        1.94555851e-05, 1.10170280e-03, 1.84511664e-04, 8.51510558e-05,\n","        9.91665900e-01, 3.42931878e-03],\n","       [7.83670112e-05, 6.05389802e-03, 6.30382856e-05, 3.88854765e-04,\n","        5.88815485e-04, 1.08228868e-03, 1.86918463e-04, 9.78682995e-01,\n","        3.43793043e-04, 1.25310542e-02],\n","       [2.75618695e-05, 1.32230751e-03, 2.51262973e-04, 3.08383344e-04,\n","        7.75893568e-05, 5.84895723e-04, 2.88734795e-04, 1.69835577e-04,\n","        2.89358757e-03, 9.94075775e-01],\n","       [2.67206669e-05, 5.00969542e-03, 3.86067026e-04, 9.87611771e-01,\n","        1.98575133e-03, 2.77273008e-03, 1.13250535e-04, 3.48455505e-04,\n","        3.04871181e-04, 1.44053122e-03],\n","       [9.85724400e-05, 3.81907848e-05, 3.46394896e-04, 1.50541004e-04,\n","        7.38219591e-04, 2.86006598e-05, 5.19814857e-05, 2.13076244e-03,\n","        2.32427055e-03, 9.94092464e-01],\n","       [5.12816303e-04, 4.22575278e-03, 8.39482469e-04, 2.21451814e-03,\n","        1.20717566e-03, 1.89959945e-04, 2.87262665e-04, 9.59940953e-04,\n","        9.87928987e-01, 1.63402921e-03],\n","       [1.14786206e-03, 2.33478160e-04, 3.37562560e-05, 1.90427614e-04,\n","        1.50159351e-03, 9.95622635e-01, 4.94951819e-05, 1.00169018e-04,\n","        1.00203429e-03, 1.18579432e-04],\n","       [6.14641700e-04, 5.68390545e-03, 3.58704099e-04, 1.21710394e-02,\n","        3.74308671e-03, 1.85585557e-03, 5.53128775e-04, 2.81695230e-03,\n","        1.49647516e-04, 9.72052991e-01],\n","       [1.38051296e-03, 1.40039861e-04, 1.79057693e-04, 9.93919134e-01,\n","        4.04995444e-06, 2.61287414e-03, 1.04291375e-05, 1.18864557e-06,\n","        1.49455073e-03, 2.58240500e-04],\n","       [3.30226822e-03, 2.85459543e-03, 5.70408825e-04, 9.89464879e-01,\n","        2.23177820e-04, 2.21769232e-03, 7.69886014e-04, 1.71003485e-04,\n","        2.72707348e-05, 3.98859469e-04],\n","       [9.99121308e-01, 1.21989558e-07, 2.99774092e-05, 3.16038844e-04,\n","        3.88353328e-05, 2.45597057e-05, 1.65886570e-06, 1.11564033e-04,\n","        3.53600393e-04, 2.31091985e-06],\n","       [2.79578683e-03, 6.72155966e-06, 2.16981760e-04, 7.11498898e-04,\n","        1.00072380e-03, 1.82299744e-04, 3.25007240e-05, 9.93965566e-01,\n","        6.07564143e-05, 1.02726603e-03],\n","       [5.02859693e-05, 5.80995111e-03, 2.62881658e-05, 1.54773565e-03,\n","        9.83309209e-01, 2.84117507e-03, 2.09534168e-03, 1.50617131e-03,\n","        1.11761627e-04, 2.70192721e-03],\n","       [3.69029149e-05, 1.84405071e-05, 1.89815517e-04, 2.86872126e-03,\n","        6.77594030e-03, 1.04477617e-03, 1.88650782e-04, 2.36578216e-03,\n","        9.09726543e-04, 9.85601187e-01],\n","       [2.01861316e-04, 7.02879697e-05, 2.84556358e-04, 2.49781850e-04,\n","        2.34687934e-04, 2.31299433e-04, 2.22776780e-05, 1.16548047e-03,\n","        9.94268835e-01, 3.27101117e-03],\n","       [9.98294353e-01, 1.88025069e-07, 1.34117564e-03, 1.27872295e-06,\n","        1.57221493e-05, 2.29147845e-05, 8.47230751e-07, 2.22244023e-04,\n","        6.60094593e-05, 3.53965333e-05],\n","       [6.54642863e-05, 1.11137815e-04, 2.59731867e-04, 3.08857052e-05,\n","        2.37953640e-03, 1.21068049e-04, 9.55758151e-05, 1.72093092e-03,\n","        5.08219586e-04, 9.94707465e-01],\n","       [7.59971663e-05, 3.70682551e-06, 2.93999328e-04, 4.37514996e-03,\n","        9.93430018e-01, 1.18418811e-05, 5.93092664e-05, 2.83310092e-05,\n","        1.81617488e-05, 1.70357293e-03],\n","       [6.70722075e-05, 9.93310034e-01, 5.97404025e-04, 2.34652209e-04,\n","        1.04626734e-03, 2.45118141e-03, 3.46843881e-05, 1.02594109e-04,\n","        2.10701046e-03, 4.91439023e-05],\n","       [1.54643226e-03, 2.78189018e-05, 1.17710046e-03, 4.69682927e-05,\n","        9.92839694e-01, 2.05620119e-04, 9.51428592e-05, 3.61244031e-03,\n","        4.02902864e-04, 4.59212461e-05],\n","       [3.46869529e-05, 2.31096218e-03, 5.86167735e-05, 2.88105832e-04,\n","        9.89854157e-01, 2.37712613e-03, 1.34946441e-03, 6.03579683e-04,\n","        8.63668742e-04, 2.25950847e-03],\n","       [1.20992796e-03, 5.03373485e-05, 9.54325442e-05, 1.41753218e-04,\n","        5.07706602e-04, 1.80052866e-05, 9.97782886e-01, 1.32063644e-06,\n","        1.58570110e-04, 3.40824081e-05],\n","       [9.96391594e-01, 5.48487151e-07, 3.69359586e-05, 1.16822007e-03,\n","        1.03287048e-05, 2.34065828e-05, 3.61710117e-05, 3.83763072e-05,\n","        2.17033224e-03, 1.24121711e-04],\n","       [1.45474577e-03, 1.44321211e-05, 2.96634011e-04, 6.04035195e-05,\n","        9.95166123e-01, 2.78956461e-04, 1.77140662e-03, 7.27433944e-04,\n","        8.69000578e-05, 1.42950099e-04],\n","       [4.90032508e-05, 2.68185255e-03, 1.11901158e-04, 6.75625692e-04,\n","        2.09581014e-03, 9.93215859e-01, 1.03086408e-04, 1.51152679e-04,\n","        4.88716178e-04, 4.26900457e-04],\n","       [1.04242109e-03, 4.57252427e-05, 9.14195698e-05, 3.57910285e-05,\n","        3.28832975e-04, 2.02966941e-04, 9.98024702e-01, 2.53055987e-06,\n","        2.25223521e-05, 2.03226882e-04],\n","       [7.81365998e-06, 9.98155117e-01, 3.93832015e-05, 1.99324437e-04,\n","        1.54690628e-04, 6.51911600e-04, 3.05174381e-05, 2.68765230e-04,\n","        2.28534002e-04, 2.63863098e-04],\n","       [9.88637567e-01, 3.53941403e-04, 6.51249057e-03, 7.10509368e-04,\n","        9.06191010e-04, 2.33315118e-03, 2.92361383e-05, 7.23839476e-05,\n","        1.81535306e-05, 4.26304177e-04],\n","       [9.94648159e-01, 3.26392602e-08, 2.54373578e-03, 1.51265890e-03,\n","        3.37628626e-05, 1.05509253e-05, 9.91119538e-04, 4.26409533e-05,\n","        1.60838434e-04, 5.63750764e-05],\n","       [4.61105847e-05, 9.89807367e-01, 6.88881439e-04, 1.64772128e-03,\n","        9.75183593e-06, 2.67451559e-03, 4.44398820e-03, 4.13179296e-05,\n","        1.01724378e-04, 5.38778200e-04],\n","       [8.41985966e-05, 2.12799205e-04, 6.36566474e-05, 8.73638874e-06,\n","        1.84899196e-03, 4.77207039e-04, 1.77855236e-05, 9.92789149e-01,\n","        1.53019155e-05, 4.48211562e-03],\n","       [6.89763601e-06, 9.96163905e-01, 5.55718616e-05, 1.63070814e-04,\n","        4.87239195e-05, 5.73895406e-04, 1.94358887e-04, 1.76362621e-04,\n","        1.11336216e-04, 2.50589638e-03],\n","       [1.91037863e-04, 1.58082531e-03, 1.96843219e-04, 4.18427044e-06,\n","        6.31269068e-04, 1.47720362e-04, 9.96298909e-01, 4.49121871e-05,\n","        6.56485790e-04, 2.47818331e-04],\n","       [4.45499354e-05, 3.54515723e-05, 2.51759247e-05, 9.98941123e-01,\n","        6.47285342e-05, 1.11030240e-04, 3.47467176e-05, 7.96237237e-06,\n","        6.94965547e-06, 7.28279119e-04],\n","       [9.96111631e-01, 9.56531494e-07, 4.33752284e-05, 3.61798075e-03,\n","        1.88186859e-05, 5.91546959e-05, 2.53250510e-05, 2.23550542e-05,\n","        6.96042116e-05, 3.07219925e-05],\n","       [5.38179302e-04, 5.91171021e-03, 9.88195240e-01, 4.11173329e-03,\n","        4.94934939e-05, 5.58789179e-04, 1.57316696e-04, 1.18416447e-05,\n","        3.86829110e-04, 7.88323086e-05],\n","       [3.84844971e-05, 9.98124421e-01, 1.21102334e-04, 2.26995224e-04,\n","        1.60619762e-04, 3.57710262e-04, 7.14759699e-06, 1.02303929e-04,\n","        8.37044558e-04, 2.41459493e-05],\n","       [1.39510876e-05, 9.91436124e-01, 4.00983263e-03, 2.08984813e-04,\n","        3.38352198e-04, 6.83652237e-04, 8.29548226e-05, 6.70879788e-04,\n","        1.29649241e-03, 1.25878048e-03],\n","       [6.12933072e-05, 4.10335808e-04, 2.87113817e-05, 4.98762029e-06,\n","        5.03496209e-04, 3.12002754e-04, 9.98520045e-06, 9.96022224e-01,\n","        1.82662683e-04, 2.46415590e-03]], dtype=float32)>"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["model(train_images)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"visualize_dense_layer.ipynb","provenance":[{"file_id":"https://github.com/keisen/tf-keras-vis/blob/release%2Fv0.6.0/examples/visualize_dense_layer.ipynb","timestamp":1621656994610}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
